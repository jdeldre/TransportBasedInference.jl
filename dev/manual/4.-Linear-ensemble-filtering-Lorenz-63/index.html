<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>4. Linear ensemble filtering for the Lorenz-63 problem · TransportBasedInference.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">TransportBasedInference.jl</span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../background/">Background</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../1.-Estimation-of-the-Banana-distribution/">1. Estimation of the Banana distribution</a></li><li><a class="tocitem" href="../3.-Structure-discovery-of-the-Lorenz-96/">3. Structure discovery for the Lorenz-96 problem</a></li><li class="is-active"><a class="tocitem" href>4. Linear ensemble filtering for the Lorenz-63 problem</a></li><li><a class="tocitem" href="../5.-Linear-ensemble-filtering-Lorenz-96-with-localization/">-</a></li><li><a class="tocitem" href="../6.-Radial-basis-nonlinear-ensemble-filtering-Lorenz-63/">-</a></li><li><a class="tocitem" href="../7.-Radial-basis-nonlinear-ensemble-filtering-Lorenz-96/">-</a></li></ul></li><li><span class="tocitem">API Documentation</span><ul><li><a class="tocitem" href="../../apidoc/">Functions</a></li></ul></li><li><span class="tocitem">Community guidelines</span><ul><li><a class="tocitem" href="../../contribute/">Contribute to TransportBasedInference.jl</a></li></ul></li><li><a class="tocitem" href="../../LICENSE/">LICENSE</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>4. Linear ensemble filtering for the Lorenz-63 problem</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>4. Linear ensemble filtering for the Lorenz-63 problem</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/mleprovost/TransportBasedInference.jl/blob/master/docs/src/manual/4.-Linear-ensemble-filtering-Lorenz-63.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id=".-Linear-ensemble-filtering-for-the-Lorenz-63-problem"><a class="docs-heading-anchor" href="#.-Linear-ensemble-filtering-for-the-Lorenz-63-problem">4. Linear ensemble filtering for the Lorenz-63 problem</a><a id=".-Linear-ensemble-filtering-for-the-Lorenz-63-problem-1"></a><a class="docs-heading-anchor-permalink" href="#.-Linear-ensemble-filtering-for-the-Lorenz-63-problem" title="Permalink"></a></h1><p>In this notebook, we are interested in the <em>filtering problem</em>, the estimation of the conditional distribution of the state variable given the knowledge of all the observations up to that time. In practice, we use a particle approximation of the filtering density, which is recursively updated in a two-step procedure: a <em>forecast</em> step and an <em>analysis</em> step.</p><p>In the forecast step, the filtering ensemble is propagated through the dynamical model to generate samples from the forecast ensemble.</p><p>The analysis step updates the forecast ensemble by assimilating the newly available observation from the true system. The resulting ensemble forms a particle approximation of the filtering density at the next step.</p><p>The analysis step does not involve time propagation and can be treated as a <em>static Bayesian problem</em>, see notebook 2. Different algorithms have been developed to perform the analysis of the measurement. In particular, the ensemble Kalman filter (EnKF) developed by Evensen <sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup> uses a linear transformation in the analysis step. This linear transformation is estimated under Gaussian assumptions. In this notebook, we apply the EnKF to the Lorenz-63 problem.</p><p>References</p><p>To perform sequential inference in <code>TransportBasedInference</code>, we need to provide the following:</p><ul><li><strong>Specify the problem</strong>: Define the state-space model: initial condition, dynamical and observation models (including process and observation noise)</li><li><strong>Specify the inflation parameters</strong>: Determine the covariance inflation to properly balance the dynamical system and the observations from the truth system</li><li><strong>Specify the filter</strong>: Choose the ensemble filter to assimilate the observations in the state estimate</li><li><strong>Perform the sequential inference</strong>: Perform the sequential inference</li></ul><pre><code class="language-">using Revise
using LinearAlgebra
using TransportBasedInference
using Statistics
using Distributions</code></pre><p>Load some packages to make nice figures</p><pre><code class="language-">using Plots
default(tickfont = font(&quot;CMU Serif&quot;, 9),
        titlefont = font(&quot;CMU Serif&quot;, 14),
        guidefont = font(&quot;CMU Serif&quot;, 12),
        legendfont = font(&quot;CMU Serif&quot;, 10),
        grid = false)
pyplot()

using LaTeXStrings
using ColorSchemes</code></pre><p>The Lorenz-63  model is a three dimensional system that models the atmospheric convection [4]. This system is a classical benchmark problem in data assimilation. The state <span>$\boldsymbol{x} = (x_1, x_2, x_3)$</span> is governed by the following set of ordinary differential equations:</p><p class="math-container">\[\begin{aligned}
&amp;\frac{\mathrm{d} x_1}{\mathrm{d} t}=\sigma(x_2-x_1)\\
&amp;\frac{\mathrm{d} x_2}{\mathrm{d} t}=x_1(\rho-x_2)-x_2\\
&amp;\frac{\mathrm{d} x_3}{\mathrm{d} t}=x_1 x_2-\beta x_3,
\end{aligned}\]</p><p>where <span>$\sigma = 10, \beta = 8/3, \rho = 28$</span>. For these values, the system is chaotic and behaves like a strange attractor. We integrate this system of ODEs with time step <span>$\Delta t_{dyn} = 0.05$</span>. The state is fully observed <span>$h(\boldsymbol{x}, t) = \boldsymbol{x}$</span> with <span>$\Delta t_{obs}=0.1$</span>. The initial distribution <span>$\pi_{\mathsf{X}_0}$</span> is the standard Gaussian. The process noise is Gaussian with zero mean and covariance <span>$10^{-4}\boldsymbol{I}_3$</span>. The measurement noise has a Gaussian distribution with zero mean and covariance <span>$\theta^2\boldsymbol{I}_3$</span> where <span>$\theta^2 = 4.0$</span>.</p><p>Simple twin-experiment</p><p>Define the dimension of the state and observation vectors</p><pre><code class="language-julia">Nx = 3
Ny = 3</code></pre><pre class="documenter-example-output">3</pre><p>Define the time steps <span>$\Delta t_{dyn}, \Delta t_{obs}$</span>  of the dynamical and observation models. Observations from the truth are assimilated every <span>$\Delta t_{obs}$</span>.</p><pre><code class="language-julia">Δtdyn = 0.05
Δtobs = 0.1</code></pre><pre class="documenter-example-output">0.1</pre><p>Define the time span of interest</p><pre><code class="language-julia">t0 = 0.0
tf = 100.0
Tf = ceil(Int64, (tf-t0)/Δtobs)</code></pre><pre class="documenter-example-output">1000</pre><p>Define the distribution for the initial condition <span>$\pi_{\mathsf{X}_0}$</span></p><pre><code class="language-">π0 = MvNormal(zeros(Nx), Matrix(1.0*I, Nx, Nx))</code></pre><p>We construct the state-space representation <code>F</code> of the system composed of the deterministic part of the dynamical and observation models.</p><p>The dynamical model is provided by the right hand side of the ODE to solve. For a system of ODEs, we will prefer an in-place syntax <code>f(du, u, p, t)</code>, where <code>p</code> are parameters of the model. We rely on <code>OrdinaryDiffEq</code> to integrate the dynamical system with the Tsitouras 5/4 Runge-Kutta method adaptive time marching.</p><p>We assume that the state is fully observable, i.e. <span>$h(x, t) = x$</span>.</p><p>Note: the right-hand-side of the Lorenz-63 model is implemented in <code>TransportBasedInference.jl</code> under the name <code>lorenz63!</code>. The code is reproduced for convenience.</p><pre><code class="language-none">function lorenz63!(du,u,p,t)
    du[1] = 10.0*(u[2]-u[1])
    du[2] = u[1]*(28.0-u[3]) - u[2]
    du[3] = u[1]*u[2] - (8/3)*u[3]
    return du
end</code></pre><pre><code class="language-">h(x, t) = x
F = StateSpace(lorenz63!, h)</code></pre><p><code>ϵx</code> defines the additive process noise applied between the forecast step and the analysis step. The process noise is applied before to sample form the likelihood.</p><p><code>ϵy</code> defines the additive observation noise.</p><p>We assume that these noises have Gaussian distribution.</p><pre><code class="language-">σx = 1e-1
σy = 4.0

ϵx = AdditiveInflation(Nx, zeros(Nx), σx)
ϵy = AdditiveInflation(Ny, zeros(Ny), σy)</code></pre><p>Different types of inflation have been implemented in <code>TransportBasedInference.jl</code>:</p><ul><li><code>IdentityInflation</code> applies the identity transformation</li><li><code>AdditiveInflation</code> applies Gaussian noise to the ensemble members</li><li><code>MultiplicativeInflation</code> increases the spread of the ensemble  about the sample mea by a multiplicative factor <span>$\beta$</span>.</li><li><code>MultiAddInflation</code> combine a multiplicative and an additive inflation.</li></ul><p>They are all subtypes of the abstract type <code>InflationType</code>.</p><p>New types of inflation can easily be created and integrated in the existing tools of <code>TransportBasedInference.jl</code>, as long as the satisfy the following requirements:</p><ul><li><code>MyInflationType &lt;: InflationType</code></li><li><code>(A::MyInflationType)(X::AbstractMatrix{Float64})</code> is defined</li></ul><pre><code class="language-">model = Model(Nx, Ny, Δtdyn, Δtobs, ϵx, ϵy, π0, 0, 0, 0, F);</code></pre><p>Set initial condition of the true system</p><pre><code class="language-">x0 = rand(model.π0)</code></pre><p>Run dynamics and generate data</p><p>For the twin-experiment, we use the function <code>generate_lorenz63</code> to integrate forward in time the Lorenz-63 ODE, and generate the observations that will be later assimilated into the ensemble filter. This function can easily be modified for your specific needs.</p><pre><code class="language-">data = generate_lorenz63(model, x0, Tf);</code></pre><p>In <code>TransportBasedInference.jl</code>, we use the following convention to store the state and observation variables. The state and observation variables of the different ensemble members are stored in a common matrix <code>X</code>. The different columns store the different samples. The first entries of a column contains the observation variables, while the latter contains the state variables. This convention might seem confusing at first, but it is very convenient for conditional density estimation, see notebook 2 or 5 for instance.</p><p>Different ensemble filters have been implemented in <code>TransportBasedInference.jl</code>:</p><ul><li><p><code>IdFilter</code>: a trivial identity filter</p></li><li><p><code>StochEnKF</code>: the stochastic version of the ensemble Kalman filter (sEnKF), Evensen [1].</p></li><li><p><code>ETKF</code>: the ensemble transform Kalman filter (ETKF) Bishop et al. [3]. This filter exactly verifies the propagation equation for the covariance matrix of the Kalman filter, and avoid to sample the observation noise. This filter belongs to the class of deterministic ensemble Kalman filters.</p></li><li><p><code>StochMapFilter</code>: the stochastic map filter (SMF) developed by Spantini et al. [5]. This filter is a nonlinear generalization of the sEnKF based on measure transport. This filter is presented in the notebooks 6 &amp; 7.</p></li></ul><p>New ensemble filter can easily be created and integrated in the existing tools of <code>TransportBasedInference.jl</code>, as long as the satisfy the following requirements:</p><ul><li><code>MyFilterType &lt;: SeqFilter</code></li><li><code>(A::MyFilterType)(X::AbstractMatrix{Float64}, ystar, t)</code> is defined, where <code>ystar</code> is the observation to assimilate in the forecast ensemble <code>X</code>.</li></ul><p>Define a stochastic ensemble Kalman filter</p><pre><code class="language-">senkf = StochEnKF(model.ϵy, model.Δtdyn, model.Δtobs)</code></pre><p>Define an ensemble transform Kalman filter</p><pre><code class="language-">etkf = ETKF(model.ϵy, model.Δtdyn, model.Δtobs, 20*model.Δtobs)</code></pre><p>Initialize the ensemble matrix <code>X</code> <span>$\in \mathbb{R}^{(N_y + N_x) \times N_e}$</span>.</p><pre><code class="language-">Ne = 100 #ensemble size
X = zeros(model.Ny + model.Nx, Ne)

# Generate the initial conditions for the state.
viewstate(X, model.Ny, model.Nx) .= rand(model.π0, Ne)</code></pre><p>Apply the sequential filter over the time window</p><p>The function <code>seqassim</code> provides a friendly API to experiment with the different ensemble filters, the tuning of the different inflation parameters...</p><pre><code class="language-">Xsenkf = seqassim(F, data, Tf, model.ϵx, senkf, deepcopy(X), model.Ny, model.Nx, t0)
nothing</code></pre><pre><code class="language-">Xetkf = seqassim(F, data, Tf, model.ϵx, etkf, deepcopy(X), model.Ny, model.Nx, t0)
nothing</code></pre><p><code>mean_hist</code> stacked together the mean of the ensemble matrices over the assimilation window.</p><pre><code class="language-">mean_hist(Xsenkf)</code></pre><pre><code class="language-"># Plot the first component of the state over time
nb = 1
ne = size(Xsenkf,1)-1
Δ = 1
plt = plot(xlim = (-Inf, Inf), ylim = (-Inf, Inf), xlabel = L&quot;t&quot;, ylabel = L&quot;x_1&quot;)
plot!(plt, data.tt[nb:Δ:ne], data.xt[1,nb:Δ:ne], linewidth =  3, color = :teal, label = &quot;True&quot;)
plot!(plt, data.tt[nb:Δ:ne], mean_hist(Xsenkf)[1,1+nb:Δ:1+ne], linewidth = 3, grid = false,
     color = :orangered2, linestyle = :dash, label = &quot;sEnKF&quot;)
scatter!(plt, data.tt[nb:Δ:ne], data.yt[1,nb:Δ:ne], linewidth = 3, color = :grey, markersize = 5, alpha = 0.5, label = &quot;Observation&quot;)
plt</code></pre><pre><code class="language-"># Plot the different component of the state over time
nb = 1
ne = size(Xsenkf,1)-1
Δ = 1
plt = plot(layout = grid(3,1), xlim = (-Inf, Inf), ylim = (-Inf, Inf), xlabel = L&quot;t&quot;,
           size = (900, 1000))

for i =1:3
    plot!(plt[i,1], data.tt[nb:Δ:ne], data.xt[i,nb:Δ:ne], linewidth =  2, color = :teal,
          ylabel = latexstring(&quot;x_&quot;*string(i)), legend = (i == 1), label = &quot;True&quot;)
    plot!(plt[i,1], data.tt[nb:Δ:ne], mean_hist(Xsenkf)[i,1+nb:Δ:1+ne], linewidth = 2, grid = false,
          color = :orangered2, linestyle = :dash, label = &quot;sEnKF&quot;)
    scatter!(plt[i,1], data.tt[nb:Δ:ne], data.yt[i,nb:Δ:ne], linewidth = 3, color = :grey,
          markersize = 5, alpha = 0.5, label  = &quot;Observation&quot;)
end

plt</code></pre><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Evensen, G., 1994. Sequential data assimilation with a nonlinear quasi‐geostrophic model using Monte Carlo methods to forecast error statistics. Journal of Geophysical Research: Oceans, 99(C5), pp.10143-10162.</li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>Asch, M., Bocquet, M. and Nodet, M., 2016. Data assimilation: methods, algorithms, and applications. Society for Industrial and Applied Mathematics.</li><li class="footnote" id="footnote-3"><a class="tag is-link" href="#citeref-3">3</a>Bishop, C.H., Etherton, B.J. and Majumdar, S.J., 2001. Adaptive sampling with the ensemble transform Kalman filter. Part I: Theoretical aspects. Monthly weather review, 129(3), pp.420-436.</li><li class="footnote" id="footnote-4"><a class="tag is-link" href="#citeref-4">4</a>Lorenz, E.N., 1963. Deterministic nonperiodic flow. Journal of atmospheric sciences, 20(2), pp.130-141.</li><li class="footnote" id="footnote-5"><a class="tag is-link" href="#citeref-5">5</a>Spantini, A., Baptista, R. and Marzouk, Y., 2019. Coupling techniques for nonlinear ensemble filtering. arXiv preprint arXiv:1907.00389.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../3.-Structure-discovery-of-the-Lorenz-96/">« 3. Structure discovery for the Lorenz-96 problem</a><a class="docs-footer-nextpage" href="../5.-Linear-ensemble-filtering-Lorenz-96-with-localization/">- »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 13 July 2021 17:25">Tuesday 13 July 2021</span>. Using Julia version 1.5.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
